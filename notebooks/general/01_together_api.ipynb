{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='8c08e943cfc35cc0-KEF', object=<ObjectType.ChatCompletion: 'chat.completion'>, created=1725903087, model='meta-llama/meta-llama-3.1-8b-instruct-turbo', choices=[ChatCompletionChoicesData(index=0, logprobs=None, finish_reason=<FinishReason.EOS: 'eos'>, message=ChatCompletionMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The city that never sleeps - New York! Located in the state of New York, on the eastern coast of the United States, New York City (NYC) is one of the world\\'s most iconic and vibrant cities. Here\\'s a brief overview:\\n\\n**History**\\n\\nNew York City was founded in 1624 by the Dutch, who named it \"New Amsterdam.\" In 1664, the British took control and renamed it \"New York\" after the Duke of York, later King James II. Throughout its history, NYC has been a melting pot of cultures, with immigrants from all over the world contributing to its growth and diversity.\\n\\n**Landmarks and Attractions**\\n\\nNew York City is home to some of the world\\'s most famous landmarks, including:\\n\\n1. **The Statue of Liberty**: A symbol of freedom and democracy, located on Liberty Island in New York Harbor.\\n2. **Central Park**: An 843-acre green oasis in the middle of Manhattan, offering walking paths, lakes, and plenty of people-watching opportunities.\\n3. **The Empire State Building**: An iconic skyscraper that was the world\\'s tallest building when it was completed in 1931.\\n4. **Times Square**: Known as the \"Crossroads of the World,\" this bustling area is famous for its bright lights, giant billboards, and lively street performers.\\n5. **The Metropolitan Museum of Art**: One of the world\\'s largest and most famous museums, with a collection of over 2 million works of art.\\n6. **Broadway**: The heart of New York\\'s theater scene, with dozens of shows and musicals to choose from.\\n7. **9/11 Memorial & Museum**: A poignant tribute to the victims of the 9/11 attacks, featuring two massive reflecting pools surrounded by the names of those who were killed.\\n\\n**Neighborhoods**\\n\\nNew York City is divided into five boroughs: Manhattan, Brooklyn, Queens, the Bronx, and Staten Island. Each borough has its own unique character and attractions, including:\\n\\n1. **Manhattan**: The most populous borough, home to many of NYC\\'s iconic landmarks, including Times Square, Central Park, and the Empire State Building.\\n2. **Brooklyn**: Known for its trendy neighborhoods, such as Williamsburg and Bushwick, as well as its famous Brooklyn Bridge.\\n3. **Queens**: The most ethnically diverse county in the United States, with a vibrant food scene and a variety of cultural attractions.\\n4. **The Bronx**: Home to the New York Yankees baseball team and the Bronx Zoo, the largest metropolitan zoo in the United States.\\n5. **Staten Island**: The smallest borough, with a more suburban feel and a beautiful waterfront park.\\n\\n**Food and Drink**\\n\\nNew York City is a food lover\\'s paradise, with a diverse range of cuisines and restaurants to choose from. Some popular options include:\\n\\n1. **Pizza**: New York-style pizza is famous for its thin crust and foldable slices.\\n2. **Bagels**: A classic New York breakfast staple, often topped with cream cheese or lox.\\n3. **Hot Dogs**: Street vendors and carts offer a variety of hot dog options, from classic to gourmet.\\n4. **Deli Sandwiches**: Classic Jewish delis serve up pastrami sandwiches, knishes, and other comfort foods.\\n5. **Desserts**: NYC is home to some of the world\\'s best desserts, including cheesecake, black and white cookies, and cannoli.\\n\\n**Culture and Entertainment**\\n\\nNew York City is a hub of culture and entertainment, with a wide range of options to suit every interest. Some popular attractions include:\\n\\n1. **Museums**: In addition to the Met, NYC is home to many other world-class museums, including the Museum of Modern Art (MoMA), the Guggenheim, and the American Museum of Natural History.\\n2. **Theater**: NYC is the heart of the American theater scene, with dozens of Broadway shows and off-Broadway productions to choose from.\\n3. **Music**: From jazz clubs to rock venues, NYC has a thriving music scene, with many famous musicians and bands getting their start in the city.\\n4. **Sports**: NYC is home to many professional sports teams, including the Yankees, the Mets, the Giants, and the Knicks.\\n5. **Nightlife**: From rooftop bars to dance clubs, NYC has a vibrant nightlife scene, with something for every taste and style.\\n\\n**Getting Around**\\n\\nNew York City has a comprehensive public transportation system, including:\\n\\n1. **Subway**: The fastest way to get around the city, with 24/7 service on many lines.\\n2. **Bus**: A convenient option for shorter trips, with many routes and schedules to choose from.\\n3. **Taxi**: A classic NYC experience, with yellow cabs available 24/7.\\n4. **Ride-hailing**: Services like Uber and Lyft are widely available in NYC.\\n5. **Walking**: A great way to explore the city, with many pedestrian-friendly streets and sidewalks.\\n\\n**Tips and Tricks**\\n\\n1. **Be prepared for crowds**: NYC is a busy city, and popular attractions can be crowded.\\n2. **Use public transportation**: It\\'s the most efficient way to get around the city.\\n3. **Tip your servers**: In NYC, it\\'s customary to tip servers at restaurants and bars.\\n4. **Respect the locals**: NYC is a city of diverse cultures and backgrounds, so be respectful of others and their traditions.\\n5. **Enjoy the energy**: NYC is a city that never sleeps, so be prepared to take in the sights, sounds, and energy of the city!\\n\\nOverall, New York City is a vibrant and exciting place to visit or live, with something for every interest and style. Whether you\\'re interested in history, culture, food, or entertainment, NYC has it all!', tool_calls=None), seed=244973614933256770)], prompt=[], usage=UsageData(prompt_tokens=40, completion_tokens=1194, total_tokens=1234))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import together\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\"..\")\n",
    "\n",
    "MODEL = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "\n",
    "\n",
    "client = together.Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"tell me about new york\"}],\n",
    ")\n",
    "# print(response.choices[0].message.content)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response format\n",
    "\n",
    "https://docs.together.ai/docs/json-mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test response format\n",
    "\n",
    "Documentation from code:\n",
    "```python\n",
    "class ChatCompletions:\n",
    "    def __init__(self, client: TogetherClient) -> None:\n",
    "        self._client = client\n",
    "\n",
    "    def create(\n",
    "        self,\n",
    "        *,\n",
    "        messages: List[Dict[str, str]],\n",
    "        model: str,\n",
    "        max_tokens: int | None = None,\n",
    "        stop: List[str] | None = None,\n",
    "        temperature: float | None = None,\n",
    "        top_p: float | None = None,\n",
    "        top_k: int | None = None,\n",
    "        repetition_penalty: float | None = None,\n",
    "        presence_penalty: float | None = None,\n",
    "        frequency_penalty: float | None = None,\n",
    "        min_p: float | None = None,\n",
    "        logit_bias: Dict[str, float] | None = None,\n",
    "        stream: bool = False,\n",
    "        logprobs: int | None = None,\n",
    "        echo: bool | None = None,\n",
    "        n: int | None = None,\n",
    "        safety_model: str | None = None,\n",
    "        response_format: Dict[str, str | Dict[str, Any]] | None = None,\n",
    "        tools: Dict[str, str | Dict[str, Any]] | None = None,\n",
    "        tool_choice: str | Dict[str, str | Dict[str, str]] | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatCompletionResponse | Iterator[ChatCompletionChunk]:\n",
    "        \"\"\"\n",
    "        Method to generate completions based on a given prompt using a specified model.\n",
    "\n",
    "        Args:\n",
    "            messages (List[Dict[str, str]]): A list of messages in the format\n",
    "                `[{\"role\": together.types.chat_completions.MessageRole, \"content\": TEXT}, ...]`\n",
    "            model (str): The name of the model to query.\n",
    "            max_tokens (int, optional): The maximum number of tokens to generate.\n",
    "                Defaults to 512.\n",
    "            stop (List[str], optional): List of strings at which to stop generation.\n",
    "                Defaults to None.\n",
    "            temperature (float, optional): A decimal number that determines the degree of randomness in the response.\n",
    "                Defaults to None.\n",
    "            top_p (float, optional): The top_p (nucleus) parameter is used to dynamically adjust the number\n",
    "                    of choices for each predicted token based on the cumulative probabilities.\n",
    "                Defaults to None.\n",
    "            top_k (int, optional): The top_k parameter is used to limit the number of choices for the\n",
    "                    next predicted word or token.\n",
    "                Defaults to None.\n",
    "            repetition_penalty (float, optional): A number that controls the diversity of generated text\n",
    "                    by reducing the likelihood of repeated sequences. Higher values decrease repetition.\n",
    "                Defaults to None.\n",
    "            presence_penalty (float, optional): A number that controls the likelihood of tokens based on if they have\n",
    "                    appeared in the text. Positive values decrease the likelihood of repeated tokens or phrases.\n",
    "                    Must be in the range [-2, 2].\n",
    "                Defaults to None.\n",
    "            frequency_penalty (float, optional): A number that controls the likelihood of tokens based on the frequency\n",
    "                    of their appearance in the text. Positive decrease the likelihood of repeated tokens or phrases.\n",
    "                    Must be in the range [-2, 2].\n",
    "                Defaults to None.\n",
    "            min_p (float, optional): A number that controls the minimum percentage value that a token must reach to\n",
    "                be considered during sampling.\n",
    "                Must be in the range [0, 1].\n",
    "                Defaults to None.\n",
    "            logit_bias (Dict[str, float], optional): A dictionary of tokens and their bias values that modify the\n",
    "                likelihood of specific tokens being sampled. Bias values must be in the range [-100, 100].\n",
    "                Defaults to None.\n",
    "            stream (bool, optional): Flag indicating whether to stream the generated completions.\n",
    "                Defaults to False.\n",
    "            logprobs (int, optional): Number of top-k logprobs to return\n",
    "                Defaults to None.\n",
    "            echo (bool, optional): Echo prompt in output. Can be used with logprobs to return prompt logprobs.\n",
    "                Defaults to None.\n",
    "            n (int, optional): Number of completions to generate. Setting to None will return a single generation.\n",
    "                Defaults to None.\n",
    "            safety_model (str, optional): A moderation model to validate tokens. Choice between available moderation\n",
    "                    models found [here](https://docs.together.ai/docs/inference-models#moderation-models).\n",
    "                Defaults to None.\n",
    "            response_format (Dict[str, Any], optional): An object specifying the format that the model must output.\n",
    "                Defaults to None.\n",
    "            tools (Dict[str, str | Dict[str, str | Dict[str, Any]]], optional): A list of tools the model may call.\n",
    "                    Currently, only functions are supported as a tool.\n",
    "                    Use this to provide a list of functions the model may generate JSON inputs for.\n",
    "                Defaults to None\n",
    "            tool_choice: Controls which (if any) function is called by the model. auto means the model can pick\n",
    "                    between generating a message or calling a function. Specifying a particular function\n",
    "                    via {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function.\n",
    "                    Sets to `auto` if None.\n",
    "                Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            ChatCompletionResponse | Iterator[ChatCompletionChunk]: Object containing the completions\n",
    "            or an iterator over completion chunks.\n",
    "        \"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='chat-7117c65e5f084d4a8131f38bb8e3454c', object=<ObjectType.ChatCompletion: 'chat.completion'>, created=1725905354, model='meta-llama/Meta-Llama-3.1-8B-Instruct', choices=[ChatCompletionChoicesData(index=0, logprobs=None, finish_reason=<FinishReason.StopSequence: 'stop'>, message=ChatCompletionMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='{\"response\": \"Bees play a crucial role in pollination, communicating through the \\'waggle dance\\' to locate food sources, and with over 20,000 species, many contribute to ecosystems, including honey bees which are known for their pollination and honey production.\" , \"citations\": [\"citation_1\", \"citation_2\", \"citation_5\"] , \"highlighted_response\": [ {\"text\": \"Bees play a crucial role in pollination,\" , \"source\": \"citation_1\"}, {\"text\": \"communicating through the \\'waggle dance\\' to locate food sources,\" , \"source\": \"citation_2\"}, {\"text\": \"and with over 20,000 species, many contribute to ecosystems,\" , \"source\": \"citation_5\"}, {\"text\": \"including honey bees which are known for their pollination and honey production.\" , \"source\": \"citation_1\"}]}', tool_calls=[]))], prompt=[], usage=UsageData(prompt_tokens=340, completion_tokens=195, total_tokens=535))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example from together website:\n",
    "import json\n",
    "from together import Together\n",
    "from pydantic import BaseModel, Field\n",
    "import together\n",
    "\n",
    "together = Together()\n",
    "\n",
    "# Define the schema for the output\n",
    "class VoiceNote(BaseModel):\n",
    "    title: str = Field(description=\"A title for the voice note\")\n",
    "    summary: str = Field(description=\"A short one sentence summary of the voice note.\")\n",
    "    actionItems: list[str] = Field(\n",
    "        description=\"A list of action items from the voice note\"\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    transcript = (\n",
    "        \"Good morning! It's 7:00 AM, and I'm just waking up. Today is going to be a busy day, \"\n",
    "        \"so let's get started. First, I need to make a quick breakfast. I think I'll have some \"\n",
    "        \"scrambled eggs and toast with a cup of coffee. While I'm cooking, I'll also check my \"\n",
    "        \"emails to see if there's anything urgent.\"\n",
    "    )\n",
    "\n",
    "    # Call the LLM with the JSON schema\n",
    "    extract = together.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"The following is a voice message transcript. Only answer in JSON.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcript,\n",
    "            },\n",
    "        ],\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"schema\": VoiceNote.model_json_schema(),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    output = json.loads(extract.choices[0].message.content)\n",
    "    print(json.dumps(output, indent=2))\n",
    "    return output\n",
    "\n",
    "main()\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class ResponseWithCitation(BaseModel):\n",
    "    \"\"\"\n",
    "    The system/user may have sent a list of citations to the LLM, e.g. 6 citations,\n",
    "    but the LLM only used 3 of them. We would also like to highlight the part of\n",
    "    the response where the LLM used the citations.\n",
    "\n",
    "    The response should contain the answer to the user question,\n",
    "    and a list of the citations used, as well as the highlighted parts of the response\n",
    "    where those citations are applied.\n",
    "    \"\"\"\n",
    "\n",
    "    response: str = Field(description=\"The full response from the LLM\")\n",
    "    citations: list[str] = Field(\n",
    "        description=\"A list of the citation ids used by the LLM in the response\"\n",
    "    )\n",
    "\n",
    "    highlighted_response: list[dict[str, str]] = Field(\n",
    "        description=\"A list of dictionaries. Each dictionary contains two keys: 'text' which represents \"\n",
    "        \"the part of the response where a citation was used, and 'citation_id' which links the \"\n",
    "        \"text to the citation source.\",\n",
    "        example=[\n",
    "            {\n",
    "                \"text\": \"This part of the response is supported by citation 1.\",\n",
    "                \"citation\": \"citation_1\",\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Another part of the response is supported by citation 2.\",\n",
    "                \"citation\": \"citation_2\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "fake_rag_data = [\n",
    "    {\n",
    "        \"id\": \"citation_1\",\n",
    "        \"text\": \"Honey bees are known for their role in pollination and for producing honey and beeswax. A single colony can contain as many as 60,000 worker bees.\",\n",
    "        \"source\": \"Encyclopedia of Pollinators\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"citation_2\",\n",
    "        \"text\": \"Bees communicate through a dance called the 'waggle dance,' which allows them to share the location of food sources with other members of the hive.\",\n",
    "        \"source\": \"Journal of Insect Behavior\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"citation_3\",\n",
    "        \"text\": \"Colony Collapse Disorder (CCD) has significantly affected bee populations worldwide, with a loss of worker bees leaving behind a queen and young bees.\",\n",
    "        \"source\": \"Global Bee Health Report\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"citation_4\",\n",
    "        \"text\": \"Bees have five eyes — two large compound eyes and three smaller ocelli — which help them detect light intensity and navigate through their environment.\",\n",
    "        \"source\": \"Insect Anatomy Review\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"citation_5\",\n",
    "        \"text\": \"There are over 20,000 species of bees, and while honey bees are the most famous, many other species play equally important roles in ecosystems.\",\n",
    "        \"source\": \"World Bee Conservation Report\",\n",
    "    },\n",
    "]\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant.\n",
    "\n",
    "You are given a message from a user and a list of citations.\n",
    "If the citations are relevant to the message, you should use them to answer the question.\n",
    "\n",
    "ONLY RESPOND IN JSON.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You will be given a message from a user and a list of sources.\n",
    "Your job is to answer the question.\n",
    "\n",
    "Here is the question:\n",
    "{question}\n",
    "\n",
    "Sources:\n",
    "{sources}\n",
    "\"\"\"\n",
    "\n",
    "SINGLE_SOURCE_TEMPLATE = \"\"\"\n",
    "```\n",
    "source_id: {source_id}\n",
    "source_text: {source_text}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def messages_with_citations(message: str, rag_data: list[dict[str, str]]):\n",
    "\n",
    "    formatted_sources = \"\"\n",
    "    for source in rag_data:\n",
    "        formatted_sources += SINGLE_SOURCE_TEMPLATE.format(\n",
    "            source_id=source[\"id\"], source_text=source[\"text\"]\n",
    "        )\n",
    "\n",
    "    user_message = PROMPT_TEMPLATE.format(question=message, sources=formatted_sources)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "    # for citation in rag_data:\n",
    "    # messages.append({\"role\": \"user\", \"content\": citation[\"text\"]})\n",
    "    return messages\n",
    "\n",
    "\n",
    "question = \"What is the role of bees in pollination?\"\n",
    "\n",
    "messages = messages_with_citations(question, fake_rag_data)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    response_format={\n",
    "        \"type\": \"json_object\",\n",
    "        \"schema\": ResponseWithCitation.model_json_schema(),\n",
    "    },\n",
    ")\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseWithCitation(response=\"Bees play a crucial role in pollination, communicating through the 'waggle dance' to locate food sources, and with over 20,000 species, many contribute to ecosystems, including honey bees which are known for their pollination and honey production.\", citations=['citation_1', 'citation_2', 'citation_5'], highlighted_response=[{'text': 'Bees play a crucial role in pollination,', 'source': 'citation_1'}, {'text': \"communicating through the 'waggle dance' to locate food sources,\", 'source': 'citation_2'}, {'text': 'and with over 20,000 species, many contribute to ecosystems,', 'source': 'citation_5'}, {'text': 'including honey bees which are known for their pollination and honey production.', 'source': 'citation_1'}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# def response_to_dict(response: together.types.chat_completions.ChatCompletionResponse):\n",
    "#     return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# d = response_to_dict(response)\n",
    "\n",
    "\n",
    "def response_to_object(\n",
    "    response: together.types.chat_completions.ChatCompletionResponse,\n",
    "):\n",
    "    return ResponseWithCitation(**json.loads(response.choices[0].message.content))\n",
    "\n",
    "\n",
    "d = response_to_object(response)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark title=\"Encyclopedia of Pollinators\">Bees play a crucial role in pollination, [citation_1]</mark> <mark title=\"Journal of Insect Behavior\">communicating through the 'waggle dance' to locate food sources, [citation_2]</mark> <mark title=\"World Bee Conservation Report\">and with over 20,000 species, many contribute to ecosystems, [citation_5]</mark> <mark title=\"Encyclopedia of Pollinators\">including honey bees which are known for their pollination and honey production. [citation_1]</mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def get_html_with_highlights(\n",
    "    response: ResponseWithCitation, rag_data: list[dict[str, str]]\n",
    "):\n",
    "    html = response.response\n",
    "    for highlight in response.highlighted_response:\n",
    "        citation_id = highlight[\"source\"]\n",
    "        citation_name = next(\n",
    "            (source[\"source\"] for source in rag_data if source[\"id\"] == citation_id),\n",
    "            \"Unknown\",\n",
    "        )\n",
    "        highlighted_text = (\n",
    "            f'<mark title=\"{citation_name}\">{highlight[\"text\"]} [{citation_id}]</mark>'\n",
    "        )\n",
    "        html = html.replace(highlight[\"text\"], highlighted_text)\n",
    "    return html\n",
    "\n",
    "\n",
    "html = get_html_with_highlights(d, fake_rag_data)\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
